{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the directory of the script being run\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# Get the parent directory of the current directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "# Add the parent directory to sys.path to make the preprocessing module discoverable\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakshitgupta/Desktop/SMU/MCDA 5580 DATA AND TEXT MINING/02 ASSIGNMENTS/ClassificationAssignment/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rakshitgupta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rakshitgupta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rakshitgupta/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/rakshitgupta/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import optuna\n",
    "from preprocessing.text_preprocessing import preprocess_data\n",
    "from utils.model_utils import save_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv', encoding='ISO-8859-1')\n",
    "columns_to_remove = ['textID', 'Time of Tweet', 'selected_text', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)']\n",
    "df_processed = preprocess_data(df, text_column_name='text', columns_to_remove=columns_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_processed['text'], df_processed['sentiment'], test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorization = TfidfVectorizer()\n",
    "XV_train = vectorization.fit_transform(x_train)\n",
    "XV_test = vectorization.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakshitgupta/Desktop/SMU/MCDA 5580 DATA AND TEXT MINING/02 ASSIGNMENTS/ClassificationAssignment/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(n_jobs=-1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(n_jobs=-1)\n",
    "lr.fit(XV_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr=lr.predict(XV_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6980171002364927"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy score\n",
    "score_lr = accuracy_score(y_test, pred_lr)\n",
    "score_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune for TfidfVectorizer\n",
    "    max_df = trial.suggest_float('max_df', 0.5, 1.0)\n",
    "    min_df = trial.suggest_int('min_df', 1, 5)\n",
    "    max_features = trial.suggest_categorical('max_features', [None, 5000, 10000, 20000])\n",
    "    \n",
    "    # Hyperparameters to tune for LogisticRegression\n",
    "    C = trial.suggest_float('C', 1e-4, 10.0)\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0, 1)  \n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet'])\n",
    "    \n",
    "    # Setup the TfidfVectorizer and LogisticRegression within a pipeline\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        lowercase=True, \n",
    "        ngram_range=(1, 2),  \n",
    "        max_df=max_df,\n",
    "        min_df=min_df,\n",
    "        max_features=max_features\n",
    "    )\n",
    "    model_lr = LogisticRegression(\n",
    "        C=C,\n",
    "        penalty=penalty,\n",
    "        l1_ratio=l1_ratio if penalty == 'elasticnet' else None,\n",
    "        solver='saga',\n",
    "        multi_class='multinomial',\n",
    "        random_state=1\n",
    "    )\n",
    "    \n",
    "    pipeline = make_pipeline(tfidf_vectorizer, model_lr)\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    # Predict and calculate accuracy\n",
    "    predictions = pipeline.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-30 22:50:18,247] A new study created in memory with name: no-name-d2955699-d2e6-416b-b450-96dff6523ae8\n",
      "[I 2024-03-30 22:51:38,107] Trial 0 finished with value: 0.704929961797344 and parameters: {'max_df': 0.900683805823834, 'min_df': 2, 'max_features': 5000, 'C': 2.57001010455713, 'l1_ratio': 0.7630220829433977, 'penalty': 'elasticnet'}. Best is trial 0 with value: 0.704929961797344.\n",
      "[I 2024-03-30 22:51:39,960] Trial 1 finished with value: 0.6851009641622703 and parameters: {'max_df': 0.6329438122455562, 'min_df': 5, 'max_features': None, 'C': 0.2730036828352817, 'l1_ratio': 0.010462947281870805, 'penalty': 'l1'}. Best is trial 0 with value: 0.704929961797344.\n",
      "[I 2024-03-30 22:51:41,596] Trial 2 finished with value: 0.674185919592505 and parameters: {'max_df': 0.9108562912898472, 'min_df': 3, 'max_features': 20000, 'C': 7.532346393691134, 'l1_ratio': 0.5104469573115292, 'penalty': 'l2'}. Best is trial 0 with value: 0.704929961797344.\n",
      "/Users/rakshitgupta/Desktop/SMU/MCDA 5580 DATA AND TEXT MINING/02 ASSIGNMENTS/ClassificationAssignment/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[I 2024-03-30 22:55:16,886] Trial 3 finished with value: 0.6807349463343642 and parameters: {'max_df': 0.5627939607808867, 'min_df': 3, 'max_features': None, 'C': 5.578097346273929, 'l1_ratio': 0.8695868798081432, 'penalty': 'elasticnet'}. Best is trial 0 with value: 0.704929961797344.\n",
      "/Users/rakshitgupta/Desktop/SMU/MCDA 5580 DATA AND TEXT MINING/02 ASSIGNMENTS/ClassificationAssignment/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[I 2024-03-30 22:56:58,758] Trial 4 finished with value: 0.676368928506458 and parameters: {'max_df': 0.5514299086982019, 'min_df': 5, 'max_features': 5000, 'C': 7.671720336778947, 'l1_ratio': 0.3784465240462829, 'penalty': 'l1'}. Best is trial 0 with value: 0.704929961797344.\n",
      "/Users/rakshitgupta/Desktop/SMU/MCDA 5580 DATA AND TEXT MINING/02 ASSIGNMENTS/ClassificationAssignment/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[I 2024-03-30 22:59:45,676] Trial 5 finished with value: 0.6734582499545206 and parameters: {'max_df': 0.6103409572717768, 'min_df': 1, 'max_features': 10000, 'C': 6.957997186725865, 'l1_ratio': 0.7818502143049821, 'penalty': 'l1'}. Best is trial 0 with value: 0.704929961797344.\n",
      "[I 2024-03-30 22:59:47,098] Trial 6 finished with value: 0.70092777878843 and parameters: {'max_df': 0.9874223677964119, 'min_df': 1, 'max_features': 5000, 'C': 0.9924803555349017, 'l1_ratio': 0.3912641417215851, 'penalty': 'l2'}. Best is trial 0 with value: 0.704929961797344.\n",
      "[I 2024-03-30 23:02:07,194] Trial 7 finished with value: 0.69674367837002 and parameters: {'max_df': 0.6269711829102675, 'min_df': 2, 'max_features': 5000, 'C': 3.7050498871927, 'l1_ratio': 0.8075405112733663, 'penalty': 'elasticnet'}. Best is trial 0 with value: 0.704929961797344.\n",
      "/Users/rakshitgupta/Desktop/SMU/MCDA 5580 DATA AND TEXT MINING/02 ASSIGNMENTS/ClassificationAssignment/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[I 2024-03-30 23:04:07,073] Trial 8 finished with value: 0.6683645624886302 and parameters: {'max_df': 0.6639411764839146, 'min_df': 3, 'max_features': 5000, 'C': 9.39663915975504, 'l1_ratio': 0.5790420788973986, 'penalty': 'l1'}. Best is trial 0 with value: 0.704929961797344.\n",
      "[I 2024-03-30 23:04:20,386] Trial 9 finished with value: 0.7105694014917228 and parameters: {'max_df': 0.8177241987849351, 'min_df': 4, 'max_features': 20000, 'C': 0.9397324550580833, 'l1_ratio': 0.5144860377924785, 'penalty': 'l1'}. Best is trial 9 with value: 0.7105694014917228.\n",
      "/Users/rakshitgupta/Desktop/SMU/MCDA 5580 DATA AND TEXT MINING/02 ASSIGNMENTS/ClassificationAssignment/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[I 2024-03-30 23:05:08,261] Trial 10 finished with value: 0.7067491358923049 and parameters: {'max_df': 0.7672167964752684, 'min_df': 4, 'max_features': 20000, 'C': 2.201153111437802, 'l1_ratio': 0.14608834678788407, 'penalty': 'l1'}. Best is trial 9 with value: 0.7105694014917228.\n",
      "/Users/rakshitgupta/Desktop/SMU/MCDA 5580 DATA AND TEXT MINING/02 ASSIGNMENTS/ClassificationAssignment/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[I 2024-03-30 23:06:06,891] Trial 11 finished with value: 0.6983809350554848 and parameters: {'max_df': 0.7686280678634836, 'min_df': 4, 'max_features': 20000, 'C': 2.6576098821134932, 'l1_ratio': 0.13416396042403259, 'penalty': 'l1'}. Best is trial 9 with value: 0.7105694014917228.\n",
      "/Users/rakshitgupta/Desktop/SMU/MCDA 5580 DATA AND TEXT MINING/02 ASSIGNMENTS/ClassificationAssignment/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[I 2024-03-30 23:06:42,071] Trial 12 finished with value: 0.7132981626341641 and parameters: {'max_df': 0.7765368470565337, 'min_df': 4, 'max_features': 20000, 'C': 1.6274446783998893, 'l1_ratio': 0.17244200389236075, 'penalty': 'l1'}. Best is trial 12 with value: 0.7132981626341641.\n",
      "/Users/rakshitgupta/Desktop/SMU/MCDA 5580 DATA AND TEXT MINING/02 ASSIGNMENTS/ClassificationAssignment/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[I 2024-03-30 23:08:08,547] Trial 13 finished with value: 0.6840094597052938 and parameters: {'max_df': 0.8391937346406821, 'min_df': 4, 'max_features': 20000, 'C': 4.623521027170983, 'l1_ratio': 0.33175371538438925, 'penalty': 'l1'}. Best is trial 12 with value: 0.7132981626341641.\n",
      "[I 2024-03-30 23:08:40,522] Trial 14 finished with value: 0.712934327815172 and parameters: {'max_df': 0.727635226125267, 'min_df': 4, 'max_features': 20000, 'C': 1.4436680017907975, 'l1_ratio': 0.626203558714046, 'penalty': 'l1'}. Best is trial 12 with value: 0.7132981626341641.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_df': 0.7765368470565337, 'min_df': 4, 'max_features': 20000, 'C': 1.6274446783998893, 'l1_ratio': 0.17244200389236075, 'penalty': 'l1'}\n",
      "Best accuracy: 0.7132981626341641\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakshitgupta/Desktop/SMU/MCDA 5580 DATA AND TEXT MINING/02 ASSIGNMENTS/ClassificationAssignment/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(max_df=0.7765368470565337, max_features=20000,\n",
       "                                 min_df=4, ngram_range=(1, 2))),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1.6274446783998893,\n",
       "                                    multi_class='multinomial', penalty='l1',\n",
       "                                    random_state=1, solver='saga'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline = make_pipeline(\n",
    "    TfidfVectorizer(\n",
    "        lowercase=True,  \n",
    "        ngram_range=(1, 2),  \n",
    "        max_df=best_params['max_df'],\n",
    "        min_df=best_params['min_df'],\n",
    "        max_features=best_params['max_features']\n",
    "    ),\n",
    "    LogisticRegression(\n",
    "        C=best_params['C'],\n",
    "        penalty=best_params['penalty'],\n",
    "        l1_ratio=best_params['l1_ratio'] if best_params['penalty'] == 'elasticnet' else None,\n",
    "        solver='saga',\n",
    "        multi_class='multinomial',\n",
    "        random_state=1\n",
    "    )\n",
    ")\n",
    "best_pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "save_model(best_pipeline, '../models/logisticRegression_classifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classificationassignment",
   "language": "python",
   "name": "classificationassignment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
